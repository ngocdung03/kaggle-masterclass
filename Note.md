##### Kaggle competitions
- Featured competitions: difficult, high prize
- Research competitions: 
    - More experimental
    - No prizes or points
- Getting-started: easiest, no prizes or points
- Playground: 
    - One step above the Getting Started
    - Trying out a new technique in a lower-skates setting
    - Small prizes
- Recruitment:
    - Uncommon
    - Interested participants can upload their resume for consideration by the host
- Annual: not strict, hosted by Kaggle twice a year.
- Limited-participation: private or invite-only.
- Formats:
    - Simple
    - Two-stage
    - Kernels only
        - More balanced as all the users have the same hardware available.

##### Kaggle datasets
- Csv, json, SQLite, archives, Big Query
- Creating a dataset:
    - Setup automatic internal updates: in case data are updated periodically.
    - Manual setting: dropdown in the data set menu header.
    - Can create a dataset from kernel's output files
    - Create a dataset and update it from one data source only.
    - To use multiple datasets in your Kernels, you need to create upload them seperately.
- Upload:
    - Option to select any organization you're a part of.
    - Dataset Collaboration allows multiple users to own and maintain a private or public dataset.
    - You can make public kernals on a private dataset and vice versa.

##### Kernels
- 2 types:
    - Scripts: files that execute everything in a sequence.
    - Notebooks: Jupiter Notebooks are composed of cells. 
- Kaggle Kernels have become a huge repository of public, open-sources, and reproducible code for Data Science and Machine Learning problems.
- Browsing Kernels tab inside a competition is a good way to get access to all the kernels associated with the specific dataset. 
- Kernel editor: editing window, console, and setting window.
    - Script are more popular for writing code for competition submisstions because of their batch execution nature.
    - Notebooks are popular for Exploratory Data Analysis and for tutorials.
    - Once the kernel is made public, it cannot be made private again. 
- Add data sources to the kernel: 
    - Launch a kernel from within a dataset or a competition.
    - Click the add data button to search for your desired dataset.
    - Can also add kernel output files up to 5GB
- Collaborating on kernels: settings/sharing option.
- Docker Container.
    - Kernel versions are not only limited to your compiled code. They include log files, output files, data sources, and more.
    - By default, the latest version of your kernel will be shown to the users in the kernel viewer. 
    - Another option for installing a package is from a configured GitHub Repository.
        - Command:[account]/[repository]
        - install_github("some_user/some_package")
    - Install custom packages using kernel editor: !pip install my-new-package
        - Upgrade/downgrade an existing package: !pip install my-existing-package==X.Y.Z
- Each Kernel Editing Session is provided with:
    - 6 hour execution time.
    - 5GB of auto-saved disk space. Directory: /kaggle/working
    - 16GB of temporary disk space.
    - CPU-only: 4 core CPU and 16GB of RAM.
    - GPU-enabled: 2 core CPU and 13GB of RAM.
    - Internet access (beta).
    - 100GB of combined size of all datasets.
    - 5GB limit for output data that a kernel can write.
    - 1 hour of idle time.
    - Commit and Run will save your changes, end the editing session, and start a new kernal execution.

##### Public API
- It is recommended to use the command line to implement it in Python: pip install kaggle
- Default location on Windows: $PYTHON_HOME/Scripts
- Authenticate API: My account/API/Create New API Token
- Using Kaggle API Directly: Provide credential at runtime: C:\Users<Windows-username>.kaggle\kaggle.json
- Using Kaggle Command Line Interface Tool: move this token to the appropriate folder to avoid any errors when using the Kaggle API.
- Interact with Kaggle competitions: 
    - Using the Command Line Interface Tools: https://github.com/Kaggle/kaggle-api
- Listing competitions and competition files: 
    - List command which lists down all the available competitions: [Listing-competitions.jpg]
    - List competition files: [Listing-competition-files.jpeg]
- Download a competition using API:
    - [Download-a-competition.jpeg]
    - Accept the rules: kaggle.com/c/<competition-name>/rules
- For datasets: 
    - Can download, create, and update previous dataset versions on Kaggle.
    - Can use third party tools along with API to schedule automatic updates of your datasets. 
    - [API-dataset.jpeg]
    - Listing and downloading: 
        - [Listing-datasets.jpeg]: kaggle datasets list -s demographics
        - [Download-datasets.jpeg]
    - Create a new dataset:
        - Create a folder containing the files. Copy the path to this folder.
        - Run the following command to generate a metadata file: [Create-metadata.jpeg]
        - Add your dataset's metadata to the generated file.
        - Run the command to create the dataset: [Create-datasets.jpeg] 
        - Create a new version of an existing dataset: You need to make sure that the ID field in the metadata points to your dataset. Check in the JSON file. Once everything is set up, you need to run the following command: [Update-datasets.jpeg] - must provide a message
        - Download metadata for an existing dataset.
        - Check status of created datasets.
- Interact with Kernels:
    - [Interact-Kernels.jpeg]
- To download Kernel metadata, pull it
- Push and pull a kernel
- Checking status and output of a kernel
- Creating and running a new Kernel: steps similar to dataset
    - [Basic-example-of-kernel-metadata.jpeg]
    - To create and run, run the command: kaggle kernels push -p/path/to/kernel
- Create and run a new version:
    - Download Kernel's most recent code and metadata files: kaggle kernels pull -k [KERNEL] -p/path/to/download -m
    - Make sure id field in the metadata points to your kernel.
    - Changing title (optional): also need to update the id field along with the title field in the next push, after renaming is complete
    - Run the updated kernel: kaggle kernels push -p/path
- Configurations: view/set/clear config values
    - Visit the offical documentation on GitHub

